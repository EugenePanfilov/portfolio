   Задачей проекта является разработка модели, которая будет предсказывать стоимость дома, основываясь на его характеристиках. 
Для оценки качества модели будут использоваться метрики MAE (Mean Absolute Error) – это среднее арифметическое модуля 
отклонения предсказанного значения от реального и MAPE (Mean Absolute Percent Error), которая показывает на сколько 
процентов в среднем предсказание модели отклоняется от реального значения.
   
   Перечислим признаки, которые содержатся в имеющихся данных и по которым будет обучаться модель: 
- статус продажи
- наличие бассейна
- тип недвижимости
- адрес
- количество ванных комнат
- год постройки дома
- год реконструкции
- тип отопления
- тип кондиционирования
- вид парковки автомобиля
- площадь земельного участка, прилагающегося к дому
- цена единицы площади участка
- наличие камина в доме
- город, в котором расположен дом
- рейтинги близлежащих школ
- расстояния до близлежащих школ
- жилая площадь
- количество спальных комнат
- штат, в котором расположен дом
- количество этажей
- уникальный идентификатор продажи
- стоимость дома 

   Сначала была проделана предобработка данных. В результате EDA получен датасет с размерностью (158778, 16). При этом 
размерность исходного датасета (377185, 18). Получено 7 числовых признаков (пропуски в них заменены на медиану, выбросы 
найдены методом IQR и удалены), 7 категориальных признаков (в них сокращено количество уникальных значений) и 2 бинарных 
признака. 

   Было обучено 3 бустинговых модели, 1 нейронная сеть, сделан стекинг. Все алгоритмы показали неудовлетворительное 
качество. Далее приводятся оценки качества на обученных моделях.


GradientBoostingRegressor

GradientBoostingRegressor(n_estimators = 1000, min_samples_split = 2, min_samples_leaf = 1, max_depth = 20, 
                          bootstrap = True, max_features = 20, learning_rate = 0.01, random_state=42)
MAE = 2080 $,     MAPE = 94 %

CatBoostRegressor

CatBoostRegressor(iterations = 5000, one_hot_max_size = 2, random_seed = 42)

MAE = 30844 $,     MAPE = 80 %

XGBRegressor

XGBRegressor(objective = 'reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.03, 
                           max_depth = 12, alpha = 1, n_jobs = -1, n_estimators = 1000)

MAE = 29809 $,     MAPE = 83 %

Stacking

Stacking (RandomForestRegressor, GradientBoostingRegressor, XGBRegressor)

MAE = 27587 $,     MAPE = 81 %

Neural Network

MAE = 49280 $,     MAPE = 98 %


   Таким образом лучшее качество показал алгоритм GradientBoostingRegressor MAE = 2080 $ и MAPE = 94 %.

В приложении 2 ноутбука: 

House_price_prediction_EDA.ipynb 

House_price_prediction_ML.ipynb

И 2 файла с данными:

data.zip с исходными данными

data_preproc.csv с предобработанными данными
