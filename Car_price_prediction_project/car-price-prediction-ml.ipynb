{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01959,
     "end_time": "2021-04-21T19:09:31.575757",
     "exception": false,
     "start_time": "2021-04-21T19:09:31.556167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Задача\n",
    "Необходимо создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам. Для оценки использовать метрику MAPE\n",
    "\n",
    "В данном ноутбуке мы выбирали лучшую модель для предсказания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017771,
     "end_time": "2021-04-21T19:09:31.611954",
     "exception": false,
     "start_time": "2021-04-21T19:09:31.594183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:31.654772Z",
     "iopub.status.busy": "2021-04-21T19:09:31.652975Z",
     "iopub.status.idle": "2021-04-21T19:09:33.549465Z",
     "shell.execute_reply": "2021-04-21T19:09:33.548213Z"
    },
    "papermill": {
     "duration": 1.919346,
     "end_time": "2021-04-21T19:09:33.549642",
     "exception": false,
     "start_time": "2021-04-21T19:09:31.630296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Импорт библиотек\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas import Series\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.model_selection import train_test_split, train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:33.593941Z",
     "iopub.status.busy": "2021-04-21T19:09:33.593293Z",
     "iopub.status.idle": "2021-04-21T19:09:35.555061Z",
     "shell.execute_reply": "2021-04-21T19:09:35.555609Z"
    },
    "papermill": {
     "duration": 1.987171,
     "end_time": "2021-04-21T19:09:35.555773",
     "exception": false,
     "start_time": "2021-04-21T19:09:33.568602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262434\n"
     ]
    }
   ],
   "source": [
    "#Импорт данных из соревнования\n",
    "data_sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "#Импорт обработанных данных\n",
    "data_full = pd.read_csv('data_full_EDA.csv') \n",
    "\n",
    "#Выбранные признаки в EDA\n",
    "data_columns = pd.read_csv('data_full_columns.csv') \n",
    "\n",
    "cat_cols = data_columns[data_columns.column_type == 'cat'].column_name.values\n",
    "bin_cols = data_columns[data_columns.column_type == 'bin'].column_name.values\n",
    "num_cols = data_columns[data_columns.column_type == 'num'].column_name.values\n",
    "\n",
    "print(len(data_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018497,
     "end_time": "2021-04-21T19:09:35.593605",
     "exception": false,
     "start_time": "2021-04-21T19:09:35.575108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Сначала выделим тестовую и тренировочную части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:35.638961Z",
     "iopub.status.busy": "2021-04-21T19:09:35.638175Z",
     "iopub.status.idle": "2021-04-21T19:09:35.761723Z",
     "shell.execute_reply": "2021-04-21T19:09:35.761180Z"
    },
    "papermill": {
     "duration": 0.148131,
     "end_time": "2021-04-21T19:09:35.761887",
     "exception": false,
     "start_time": "2021-04-21T19:09:35.613756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = data_full[data_full.sample_ == 0]\n",
    "data_test = data_full[data_full.sample_ == 1].drop(['price', 'sample_'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018689,
     "end_time": "2021-04-21T19:09:35.799833",
     "exception": false,
     "start_time": "2021-04-21T19:09:35.781144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Делим данные на еще один тест и трейн, для валидации,\n",
    "чтобы проверить, как хорошо модель работает, до отправки submission на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:35.899753Z",
     "iopub.status.busy": "2021-04-21T19:09:35.898472Z",
     "iopub.status.idle": "2021-04-21T19:09:36.195227Z",
     "shell.execute_reply": "2021-04-21T19:09:36.194623Z"
    },
    "papermill": {
     "duration": 0.376397,
     "end_time": "2021-04-21T19:09:36.195372",
     "exception": false,
     "start_time": "2021-04-21T19:09:35.818975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data_train.drop(['price', 'sample_'], axis=1).values\n",
    "Y = data_train['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.241354Z",
     "iopub.status.busy": "2021-04-21T19:09:36.240653Z",
     "iopub.status.idle": "2021-04-21T19:09:36.244647Z",
     "shell.execute_reply": "2021-04-21T19:09:36.244015Z"
    },
    "papermill": {
     "duration": 0.030188,
     "end_time": "2021-04-21T19:09:36.244780",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.214592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "\n",
    "def learn_model(model):        \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)    \n",
    "    print (f\"Точность модели по метрике MAPE: {(mape(y_test, y_pred))*100:0.2f}%\")\n",
    "    \n",
    "def learn_model_log(model):\n",
    "    model.fit(X_train,np.log(y_train+1))\n",
    "    y_pred = np.exp(model.predict(X_test))\n",
    "    print (f\"Точность модели по метрике MAPE: {(mape(y_test, y_pred))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.287249Z",
     "iopub.status.busy": "2021-04-21T19:09:36.286612Z",
     "iopub.status.idle": "2021-04-21T19:09:36.291141Z",
     "shell.execute_reply": "2021-04-21T19:09:36.291629Z"
    },
    "papermill": {
     "duration": 0.027379,
     "end_time": "2021-04-21T19:09:36.291805",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.264426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019173,
     "end_time": "2021-04-21T19:09:36.330616",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.311443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Далее попробуем построить разные модели и посмотрим их метрики. Все модели закомментируем, чтобы не грузить ноутбук. В комментариях пропишем метрики. Оставим для загрузки только лучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019159,
     "end_time": "2021-04-21T19:09:36.369253",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.350094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Наивная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.413368Z",
     "iopub.status.busy": "2021-04-21T19:09:36.412083Z",
     "iopub.status.idle": "2021-04-21T19:09:36.415779Z",
     "shell.execute_reply": "2021-04-21T19:09:36.415117Z"
    },
    "papermill": {
     "duration": 0.027304,
     "end_time": "2021-04-21T19:09:36.415916",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.388612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#learn_model(LinearRegression())\n",
    "#Точность модели по метрике MAPE: 87.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019321,
     "end_time": "2021-04-21T19:09:36.455443",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.436122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Простые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.502795Z",
     "iopub.status.busy": "2021-04-21T19:09:36.501826Z",
     "iopub.status.idle": "2021-04-21T19:09:36.506441Z",
     "shell.execute_reply": "2021-04-21T19:09:36.505777Z"
    },
    "papermill": {
     "duration": 0.031613,
     "end_time": "2021-04-21T19:09:36.506582",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.474969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = LinearRegression().fit(X_train, np.log(y_train+1))\\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(lr.predict(X_test))))*100:0.2f}%\")\\nVERSION = 1\\npredict_test = np.exp(lr.predict(X_test))\\npredict_submission = np.exp(lr.predict(data_test))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Построим линейную регрессию с логарифмированием целевой переменной\n",
    "\"\"\"\n",
    "lr = LinearRegression().fit(X_train, np.log(y_train+1))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(lr.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 1\n",
    "predict_test = np.exp(lr.predict(X_test))\n",
    "predict_submission = np.exp(lr.predict(data_test))\n",
    "\"\"\"\n",
    "# Точность модели по метрике MAPE: 20.95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.552856Z",
     "iopub.status.busy": "2021-04-21T19:09:36.551964Z",
     "iopub.status.idle": "2021-04-21T19:09:36.556682Z",
     "shell.execute_reply": "2021-04-21T19:09:36.556189Z"
    },
    "papermill": {
     "duration": 0.029972,
     "end_time": "2021-04-21T19:09:36.556826",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.526854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrf = RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1).fit(X_train, np.log(y_train+1))\\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(rf.predict(X_test))))*100:0.2f}%\")\\nVERSION = 2\\npredict_test = np.exp(rf.predict(X_test))\\npredict_submission = np.exp(rf.predict(data_test))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest\n",
    "\"\"\"\n",
    "rf = RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1).fit(X_train, np.log(y_train+1))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(rf.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 2\n",
    "predict_test = np.exp(rf.predict(X_test))\n",
    "predict_submission = np.exp(rf.predict(data_test))\n",
    "\"\"\"\n",
    "# Точность модели по метрике MAPE: 13.95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.607375Z",
     "iopub.status.busy": "2021-04-21T19:09:36.606574Z",
     "iopub.status.idle": "2021-04-21T19:09:36.611932Z",
     "shell.execute_reply": "2021-04-21T19:09:36.611226Z"
    },
    "papermill": {
     "duration": 0.033545,
     "end_time": "2021-04-21T19:09:36.612094",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.578549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrandom_grid = {\\'n_estimators\\': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\\n               \\'max_features\\': [\\'auto\\', \\'sqrt\\'],\\n               \\'max_depth\\': [int(x) for x in np.linspace(10, 110, num = 11)],\\n               \\'min_samples_split\\': [2, 5, 10],\\n               \\'min_samples_leaf\\': [1, 2, 4],\\n               \\'bootstrap\\': [True, False]}\\n\\nrf = RandomForestRegressor(random_state=RANDOM_SEED)\\nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, \\n                               cv=3, verbose=2, random_state=RANDOM_SEED, n_jobs=-1)\\nrf_random.fit(X_train, np.log(y_train+1))\\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(rf_random.predict(X_test))))*100:0.2f}%\")\\nVERSION = 8\\npredict_test = np.exp(rf.predict(X_test))\\npredict_submission = np.exp(rf.predict(data_test))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подбор параметров для Random forest\n",
    "\"\"\"\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, \n",
    "                               cv=3, verbose=2, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rf_random.fit(X_train, np.log(y_train+1))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(rf_random.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 8\n",
    "predict_test = np.exp(rf.predict(X_test))\n",
    "predict_submission = np.exp(rf.predict(data_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.661585Z",
     "iopub.status.busy": "2021-04-21T19:09:36.660657Z",
     "iopub.status.idle": "2021-04-21T19:09:36.664176Z",
     "shell.execute_reply": "2021-04-21T19:09:36.663636Z"
    },
    "papermill": {
     "duration": 0.030641,
     "end_time": "2021-04-21T19:09:36.664314",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.633673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#еще парочка экспериментов\n",
    "\n",
    "#learn_model_log(KNeighborsRegressor(algorithm = 'ball_tree', weights = 'distance', p=1))\n",
    "#Точность модели по метрике MAPE: 66.25% по-умолчанию\n",
    "#Точность модели по метрике MAPE: 59.54% p=1\n",
    "#Точность модели по метрике MAPE: 66.24% algorithm = 'ball_tree'\n",
    "#Точность модели по метрике MAPE: 63.98% weights = 'distance'\n",
    "#Точность модели по метрике MAPE: 66.25% leaf_size = 5\n",
    "#Точность модели по метрике MAPE: 57.66% algorithm = 'ball_tree', weights = 'distance', p=1\n",
    "\n",
    "#learn_model_log(KNeighborsRegressor(algorithm = 'ball_tree', weights = 'distance', p=1))\n",
    "#Точность модели по метрике MAPE: 50.23%\n",
    "\n",
    "#learn_model(DecisionTreeRegressor(random_state = 42))\n",
    "#Точность модели по метрике MAPE: 110.55% max_depth=3, max_features=20\n",
    "#Точность модели по метрике MAPE: 45.65% max_depth=15, max_features=5\n",
    "#Точность модели по метрике MAPE: 22.29% max_depth=10\n",
    "#Точность модели по метрике MAPE: 19.79% по-умолчанию\n",
    "#Точность модели по метрике MAPE: 17.50% max_depth=15\n",
    "\n",
    "#learn_model_log(DecisionTreeRegressor(max_depth=15, random_state = 42))\n",
    "#Точность модели по метрике MAPE: 19.46% по-умолчанию\n",
    "#Точность модели по метрике MAPE: 60.92% max_depth=3, max_features=20\n",
    "#Точность модели по метрике MAPE: 38.89% max_depth=15, max_features=5\n",
    "#Точность модели по метрике MAPE: 19.26% max_depth=10\n",
    "#Точность модели по метрике MAPE: 16.56% max_depth=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02097,
     "end_time": "2021-04-21T19:09:36.706558",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.685588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.754470Z",
     "iopub.status.busy": "2021-04-21T19:09:36.753784Z",
     "iopub.status.idle": "2021-04-21T19:09:36.758142Z",
     "shell.execute_reply": "2021-04-21T19:09:36.757609Z"
    },
    "papermill": {
     "duration": 0.030342,
     "end_time": "2021-04-21T19:09:36.758273",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.727931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncb = CatBoostRegressor(iterations = 5000, random_seed = RANDOM_SEED, eval_metric=\\'MAPE\\',                             custom_metric=[\\'R2\\', \\'MAE\\'], silent=True,)\\ncb.fit(X_train, np.log(y_train+1), eval_set=(X_test, np.log(y_test+1)), verbose_eval=0, use_best_model=True)\\ncb.save_model(\\'catboost_single_model_2_baseline.model\\')\\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(cb.predict(X_test))))*100:0.2f}%\")\\nVERSION = 3\\npredict_test = np.exp(cb.predict(X_test))\\npredict_submission = np.exp(cb.predict(data_test))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoostRegressor\n",
    "\"\"\"\n",
    "cb = CatBoostRegressor(iterations = 5000, random_seed = RANDOM_SEED, eval_metric='MAPE', \\\n",
    "                            custom_metric=['R2', 'MAE'], silent=True,)\n",
    "cb.fit(X_train, np.log(y_train+1), eval_set=(X_test, np.log(y_test+1)), verbose_eval=0, use_best_model=True)\n",
    "cb.save_model('catboost_single_model_2_baseline.model')\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(cb.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 3\n",
    "predict_test = np.exp(cb.predict(X_test))\n",
    "predict_submission = np.exp(cb.predict(data_test))\n",
    "\"\"\"\n",
    "# Точность модели по метрике MAPE: 13.51%\n",
    "# Kaggle 19.66459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.806830Z",
     "iopub.status.busy": "2021-04-21T19:09:36.806138Z",
     "iopub.status.idle": "2021-04-21T19:09:36.809185Z",
     "shell.execute_reply": "2021-04-21T19:09:36.809776Z"
    },
    "papermill": {
     "duration": 0.030139,
     "end_time": "2021-04-21T19:09:36.809940",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.779801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngb = GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300)\\ngb.fit(X_train, np.log(y_train+1))\\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(gb.predict(X_test))))*100:0.2f}%\")\\nVERSION = 4\\npredict_test = np.exp(gb.predict(X_test))\\npredict_submission = np.exp(gb.predict(data_test))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "\"\"\"\n",
    "gb = GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300)\n",
    "gb.fit(X_train, np.log(y_train+1))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(gb.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 4\n",
    "predict_test = np.exp(gb.predict(X_test))\n",
    "predict_submission = np.exp(gb.predict(data_test))\"\"\"\n",
    "# Точность модели по метрике MAPE: 13.68%\n",
    "# Kaggle 18.86542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:09:36.858887Z",
     "iopub.status.busy": "2021-04-21T19:09:36.857391Z",
     "iopub.status.idle": "2021-04-21T19:15:06.611496Z",
     "shell.execute_reply": "2021-04-21T19:15:06.612057Z"
    },
    "papermill": {
     "duration": 329.779933,
     "end_time": "2021-04-21T19:15:06.612289",
     "exception": false,
     "start_time": "2021-04-21T19:09:36.832356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели по метрике MAPE: 13.49%\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "xb = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.5, learning_rate=0.03, \\\n",
    "                      max_depth=12, alpha=1, n_jobs=-1, n_estimators=1000)\n",
    "xb.fit(X_train, np.log(y_train+1))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, np.exp(xb.predict(X_test))))*100:0.2f}%\")\n",
    "VERSION = 5\n",
    "predict_test = np.exp(xb.predict(X_test))\n",
    "predict_submission = np.exp(xb.predict(data_test))\n",
    "# Точность модели по метрике MAPE: 13.31%\n",
    "# Kaggle 18.84844"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02265,
     "end_time": "2021-04-21T19:15:06.659726",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.637076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:15:06.714183Z",
     "iopub.status.busy": "2021-04-21T19:15:06.713321Z",
     "iopub.status.idle": "2021-04-21T19:15:06.718878Z",
     "shell.execute_reply": "2021-04-21T19:15:06.718345Z"
    },
    "papermill": {
     "duration": 0.036474,
     "end_time": "2021-04-21T19:15:06.719060",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.682586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler() \\nX_train = scaler.fit_transform(X_train) \\nX_test = scaler.transform(X_test) \\ndata_test = scaler.transform(data_test)\\n\\ny_train = y_train \\ny_test = y_test\\n\\ncv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\\n\\ndef compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\\n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \\n\\n    splits = cv.split(X_train)\\n    for train_fold_index, predict_fold_index in splits:\\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\\n        y_fold_train = y_train[train_fold_index]\\n\\n        folded_regr = clone(regr)\\n        folded_regr.fit(X_fold_train, y_fold_train)\\n\\n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\\n\\n    meta_regr = clone(regr)\\n    meta_regr.fit(X_train, y_train)\\n\\n    X_meta_test = meta_regr.predict(X_test)\\n    X_meta_pred = meta_regr.predict(data_test)\\n\\n    return X_meta_train, X_meta_test, X_meta_pred\\n\\ndef generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\\n    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \\n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\\n    return stacked_features_train, stacked_features_test, stacked_features_pred\\n\\nregr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \\n                             max_features=3, max_depth=19, bootstrap=True, random_state=RANDOM_SEED)\\n\\nstacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\\n                            regr,\\n                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\\n                            ExtraTreesRegressor(random_state=RANDOM_SEED), \\n                            RandomForestRegressor(random_state=RANDOM_SEED, max_depth=15) ], X_train, X_test, y_train, cv, data_test)\\n\\ndef compute_metric(regr, X_train, y_train, X_test, y_test): \\n    regr.fit(X_train, y_train) \\n    y_test_pred = regr.predict(X_test) \\n    return np.round(mape(y_test, y_test_pred)*100, 4)\\n\\nprint(f\"Точность модели по метрике MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\\nVERSION = 6\\npredict_test = regr.predict(stacked_features_test)\\npredict_submission = regr.predict(stacked_features_pred)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "y_train = y_train \n",
    "y_test = y_test\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "def compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n",
    "\n",
    "    splits = cv.split(X_train)\n",
    "    for train_fold_index, predict_fold_index in splits:\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "\n",
    "        folded_regr = clone(regr)\n",
    "        folded_regr.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n",
    "\n",
    "    meta_regr = clone(regr)\n",
    "    meta_regr.fit(X_train, y_train)\n",
    "\n",
    "    X_meta_test = meta_regr.predict(X_test)\n",
    "    X_meta_pred = meta_regr.predict(data_test)\n",
    "\n",
    "    return X_meta_train, X_meta_test, X_meta_pred\n",
    "\n",
    "def generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\n",
    "    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \n",
    "    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n",
    "    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n",
    "    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n",
    "    return stacked_features_train, stacked_features_test, stacked_features_pred\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n",
    "                             max_features=3, max_depth=19, bootstrap=True, random_state=RANDOM_SEED)\n",
    "\n",
    "stacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\n",
    "                            regr,\n",
    "                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\n",
    "                            ExtraTreesRegressor(random_state=RANDOM_SEED), \n",
    "                            RandomForestRegressor(random_state=RANDOM_SEED, max_depth=15) \\\n",
    "], X_train, X_test, y_train, cv, data_test)\n",
    "\n",
    "def compute_metric(regr, X_train, y_train, X_test, y_test): \n",
    "    regr.fit(X_train, y_train) \n",
    "    y_test_pred = regr.predict(X_test) \n",
    "    return np.round(mape(y_test, y_test_pred)*100, 4)\n",
    "\n",
    "print(f\"Точность модели по метрике MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\n",
    "VERSION = 6\n",
    "predict_test = regr.predict(stacked_features_test)\n",
    "predict_submission = regr.predict(stacked_features_pred)\n",
    "\"\"\"\n",
    "# Точность модели по метрике MAPE: 15.2942%\n",
    "# Kaggle 22.59028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:15:06.774082Z",
     "iopub.status.busy": "2021-04-21T19:15:06.773333Z",
     "iopub.status.idle": "2021-04-21T19:15:06.776470Z",
     "shell.execute_reply": "2021-04-21T19:15:06.776969Z"
    },
    "papermill": {
     "duration": 0.034445,
     "end_time": "2021-04-21T19:15:06.777151",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.742706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler() \\nX_train = scaler.fit_transform(X_train) \\nX_test = scaler.transform(X_test) \\ndata_test = scaler.transform(data_test)\\n\\ny_train = y_train\\ny_test = y_test\\n\\ncv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\\n\\ndef compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\\n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \\n\\n    splits = cv.split(X_train)\\n    for train_fold_index, predict_fold_index in splits:\\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\\n        y_fold_train = y_train[train_fold_index]\\n\\n        folded_regr = clone(regr)\\n        folded_regr.fit(X_fold_train, y_fold_train)\\n\\n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\\n\\n    meta_regr = clone(regr)\\n    meta_regr.fit(X_train, y_train)\\n\\n    X_meta_test = meta_regr.predict(X_test)\\n    X_meta_pred = meta_regr.predict(data_test)\\n\\n    return X_meta_train, X_meta_test, X_meta_pred\\n\\ndef generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\\n    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \\n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\\n    return stacked_features_train, stacked_features_test, stacked_features_pred\\n\\nregr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \\n                             max_features=3, max_depth=25, bootstrap=True, random_state=RANDOM_SEED)\\n\\nstacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\\n                            regr,\\n                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\\n                            ExtraTreesRegressor(random_state=RANDOM_SEED),\\n                            GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300),\\n                            RandomForestRegressor(random_state=RANDOM_SEED, n_jobs = -1, max_depth=15) ], X_train, X_test, y_train, cv, data_test)\\n\\ndef compute_metric(regr, X_train, y_train, X_test, y_test): \\n    regr.fit(X_train, np.log(y_train+1))\\n    y_test_pred = np.exp(regr.predict(X_test))\\n    return np.round(mape(y_test, y_test_pred)*100, 4)\\n\\nprint(f\"Точность модели по метрике MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\\nVERSION = 7\\npredict_test = np.exp(regr.predict(stacked_features_test))\\npredict_submission = np.exp(regr.predict(stacked_features_pred))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "def compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n",
    "\n",
    "    splits = cv.split(X_train)\n",
    "    for train_fold_index, predict_fold_index in splits:\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "\n",
    "        folded_regr = clone(regr)\n",
    "        folded_regr.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n",
    "\n",
    "    meta_regr = clone(regr)\n",
    "    meta_regr.fit(X_train, y_train)\n",
    "\n",
    "    X_meta_test = meta_regr.predict(X_test)\n",
    "    X_meta_pred = meta_regr.predict(data_test)\n",
    "\n",
    "    return X_meta_train, X_meta_test, X_meta_pred\n",
    "\n",
    "def generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\n",
    "    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \n",
    "    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n",
    "    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n",
    "    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n",
    "    return stacked_features_train, stacked_features_test, stacked_features_pred\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n",
    "                             max_features=3, max_depth=25, bootstrap=True, random_state=RANDOM_SEED)\n",
    "\n",
    "stacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\n",
    "                            regr,\n",
    "                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\n",
    "                            ExtraTreesRegressor(random_state=RANDOM_SEED),\n",
    "                            GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300),\n",
    "                            RandomForestRegressor(random_state=RANDOM_SEED, n_jobs = -1, max_depth=15) \\\n",
    "], X_train, X_test, y_train, cv, data_test)\n",
    "\n",
    "def compute_metric(regr, X_train, y_train, X_test, y_test): \n",
    "    regr.fit(X_train, np.log(y_train+1))\n",
    "    y_test_pred = np.exp(regr.predict(X_test))\n",
    "    return np.round(mape(y_test, y_test_pred)*100, 4)\n",
    "\n",
    "print(f\"Точность модели по метрике MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\n",
    "VERSION = 7\n",
    "predict_test = np.exp(regr.predict(stacked_features_test))\n",
    "predict_submission = np.exp(regr.predict(stacked_features_pred))\n",
    "\"\"\"\n",
    "# Точность модели по метрике MAPE: 13.8579%\n",
    "# Kaggle 20.63917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023825,
     "end_time": "2021-04-21T19:15:06.825105",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.801280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Выводы следующие:\n",
    "1. Catboost достаточно хороший алгоритм, и работает даже с пропусками.\n",
    "2. Превзойти результат Catboost удалось только с xgboost. Его и будем использовать в соревовании\n",
    "3. Метрику сильно улучшает логарифмирование целевой переменной\n",
    "4. Обучение больших датасетов (250к обьектов и 20+ признаков) требует хороших ресурсов. Не все можно запустить на кагле (например, глубина дерева, поиск гиперпараметров и подобное вылетают с ошибкой нехватки памяти...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024002,
     "end_time": "2021-04-21T19:15:06.873304",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.849302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Что бы мы сделали еще, но из-за ограниченности по времени, оставим в таком виде:\n",
    "1. Изменить способ кодирования признаков\n",
    "2. Попробовать использовать признак с моделями авто, который мы удалили\n",
    "3. Прологарифмировать все числовые признаки\n",
    "4. Сделать целевую переменную категориальной (в диапазоне +-2сигма с шагом 10к) и применить модели классификации\n",
    "5. Попробовать стекинг лучших алгоритмов GradientBoostingRegressor, XGBRegressor и Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023513,
     "end_time": "2021-04-21T19:15:06.921451",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.897938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T19:15:06.972674Z",
     "iopub.status.busy": "2021-04-21T19:15:06.972045Z",
     "iopub.status.idle": "2021-04-21T19:15:07.104042Z",
     "shell.execute_reply": "2021-04-21T19:15:07.103299Z"
    },
    "papermill": {
     "duration": 0.159006,
     "end_time": "2021-04-21T19:15:07.104181",
     "exception": false,
     "start_time": "2021-04-21T19:15:06.945175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sell_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100575026</td>\n",
       "      <td>6.647342e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100549428</td>\n",
       "      <td>9.433365e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100658222</td>\n",
       "      <td>9.253898e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100937408</td>\n",
       "      <td>7.476332e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101037972</td>\n",
       "      <td>8.538589e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100912634</td>\n",
       "      <td>8.225001e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1101228730</td>\n",
       "      <td>7.155538e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1100165896</td>\n",
       "      <td>4.709632e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1100768262</td>\n",
       "      <td>1.925684e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1101218501</td>\n",
       "      <td>1.045331e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sell_id         price\n",
       "0  1100575026  6.647342e+05\n",
       "1  1100549428  9.433365e+05\n",
       "2  1100658222  9.253898e+05\n",
       "3  1100937408  7.476332e+05\n",
       "4  1101037972  8.538589e+05\n",
       "5  1100912634  8.225001e+05\n",
       "6  1101228730  7.155538e+05\n",
       "7  1100165896  4.709632e+05\n",
       "8  1100768262  1.925684e+06\n",
       "9  1101218501  1.045331e+06"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict_test = np.exp(model.predict(X_test))\n",
    "#predict_submission = np.exp(model.predict(data_test))\n",
    "\n",
    "data_sample['price'] = predict_submission\n",
    "data_sample.to_csv(f'submission_2_v{VERSION}.csv', index=False)\n",
    "data_sample.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 343.006564,
   "end_time": "2021-04-21T19:15:07.940363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-21T19:09:24.933799",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
